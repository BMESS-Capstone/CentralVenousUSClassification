{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/RJ/Desktop/AIVascularSegmentation-master/env/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "from mrcnnconfig import *\n",
    "from mrcnnmodel import *\n",
    "from mrcnnutils import *\n",
    "from mrcnnvisualize import *\n",
    "import numpy as np\n",
    "import imgaug.augmenters as aug\n",
    "import argparse\n",
    "from keras.utils import to_categorical\n",
    "print(tf.__version__)\n",
    "class VesselConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"vessels\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 2\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 3  # background + 2 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor size in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 64\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 1200\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 8\n",
    "\n",
    "    # Only accept detections if 95% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.95\n",
    "    RPN_NMS_THRESHOLD = 0.7\n",
    "\t\n",
    "    LEARNING_RATE = 0.001\n",
    "\t\n",
    "    BACKBONE = \"resnet50\"\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    \n",
    "    IMAGE_CHANNEL_COUNT = 1\n",
    "    MEAN_PIXEL = np.array([70.0])\n",
    "\t\n",
    "    MAX_GT_INSTANCES = 100\n",
    "    \n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    \n",
    "    LOSS_WEIGHTS = {\"rpn_class_loss\": 1., \"rpn_bbox_loss\": 1., \"mrcnn_class_loss\": 1., \"mrcnn_bbox_loss\": 1.,\"mrcnn_mask_loss\": 1.}\n",
    "\t\n",
    "    PATIENCE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VesselDataset(Dataset):\n",
    "    start_idx = 0\n",
    "    def load_images(self, start_idx, end_idx):\n",
    "        self.start_idx = start_idx\n",
    "        self.add_class(\"vessels\", 1, \"carotid\")\n",
    "        self.add_class(\"vessels\", 2, \"jugular\")\n",
    "        for i in range(start_idx, end_idx):\n",
    "            self.add_image(\"vessels\", image_id=i, path=None)\n",
    "    def load_image(self, image_id):\n",
    "        print(image_id + self.start_idx)\n",
    "        image = (X[image_id + self.start_idx]*255).astype(np.int32)\n",
    "        return image\n",
    "\t\t#image = np.tile(np.expand_dims(image, axis=2), (1,1,3)) # Convert grayscale to RBG\n",
    "        #return np.squeeze(image, axis=2)\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"vessels\":\n",
    "            return info[\"vessels\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "    def load_mask(self, image_id):\n",
    "        mask = Y[image_id + self.start_idx].astype(np.int32)\n",
    "        mask = to_categorical(mask).astype(np.int32)\n",
    "        mask = np.delete(mask, 0, 2) # Delete background class channel\n",
    "        return mask.astype(np.bool), np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before args parsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-gpu GPU_COUNT] [-ipg IMGS_PER_GPU]\n",
      "                             [-lr LEARNING_RATE] [-p PATIENCE]\n",
      "                             [-wd WEIGHT_DECAY] [-spe STEPS_PER_EPOCH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/RJ/Library/Jupyter/runtime/kernel-4dc4c1a0-0203-477c-8465-d99165155d22.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RJ/Desktop/AIVascularSegmentation-master/env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before args parsed\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-gpu', '--gpu_count', type=int)\n",
    "parser.add_argument('-ipg', '--imgs_per_gpu', type=int)\n",
    "parser.add_argument('-lr', '--learning_rate', type=float)\n",
    "parser.add_argument('-p', '--patience', type=int)\n",
    "parser.add_argument('-wd', '--weight_decay', type=float)\n",
    "parser.add_argument('-spe', '--steps_per_epoch', type=int)\n",
    "args = parser.parse_args()\n",
    "print(\"Args parsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up model config. Change defaults if supplied as command args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1a6877ad8afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVesselConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPU_COUNT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs_per_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPU_COUNT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs_per_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "config = VesselConfig()\n",
    "if args.gpu_count:\n",
    "\tconfig.GPU_COUNT = args.gpu_count\n",
    "if args.imgs_per_gpu:\n",
    "\tconfig.GPU_COUNT = args.imgs_per_gpu\n",
    "if args.learning_rate:\n",
    "\tconfig.GPU_COUNT = args.learning_rate\n",
    "if args.patience:\n",
    "\tconfig.GPU_COUNT = args.patience\n",
    "if args.weight_decay:\n",
    "\tconfig.GPU_COUNT = args.weight_decay\n",
    "if args.steps_per_epoch:\n",
    "\tconfig.GPU_COUNT = args.steps_per_epoch\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL SHAPES: (2439, 1, 256, 256) (2439, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/RJ/Desktop/OneDrive-2021-05-11/'\n",
    "X = np.load(data_path + 'Images.npy')\n",
    "Y = np.load(data_path + 'Labels.npy')\n",
    "print(\"ORIGINAL SHAPES:\",X.shape,Y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.squeeze(X, axis=1)\n",
    "Y = np.squeeze(Y, axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2439, 256, 256, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.expand_dims(X, axis=3)\n",
    "Y = np.expand_dims(Y, axis=3)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******SET B******\")\n",
    "permut = list(range(0,1012)) + list(range(1432,1714)) + list(range(1792,2021)) + list(range(2108,2314)) + list(range(2369,2439)) # train\n",
    "permut += list(range(1714,1792)) + list(range(2021,2108)) # val\n",
    "permut += list(range(1012,1432)) + list(range(2314,2369)) # test\n",
    "train_start = 0\n",
    "train_end = 1799\n",
    "val_start = 1799\n",
    "val_end = 1964\n",
    "test_start = 1964\n",
    "test_end = 2439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******SET C******\")\n",
    "permut = list(range(78,1432)) + list(range(1714,2108)) + list(range(2215,2369)) # train\n",
    "permut += list(range(0,78)) + list(range(2108,2215)) # val\n",
    "permut += list(range(1432,1714)) + list(range(2369,2439)) # test\n",
    "train_start = 0\n",
    "train_end = 1902\n",
    "val_start = 1902\n",
    "val_end = 2087\n",
    "test_start = 2087\n",
    "test_end = 2439\n",
    "'''\n",
    "print(\"******SET D******\")\n",
    "permut = list(range(0,611)) + list(range(1012,1792)) + list(range(1865,1955)) + list(range(2021,2215)) + list(range(2295,2439)) # train\n",
    "permut += list(range(1792,1865)) + list(range(1955,2021)) # val\n",
    "permut += list(range(611,1012)) + list(range(2215,2295)) # test\n",
    "train_start = 0\n",
    "train_end = 1819\n",
    "val_start = 1819\n",
    "val_end = 1958\n",
    "test_start = 1958\n",
    "test_end = 2439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STATS\", len(permut), X.shape[0])\n",
    "assert len(permut) == X.shape[0]\n",
    "permut = np.array(permut)\n",
    "print(permut)\n",
    "X = X[permut]\n",
    "Y = Y[permut]\n",
    "X /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[test_start:test_end]\n",
    "Y_test = Y[test_start:test_end]\n",
    "X_val = X[val_start:val_end]\n",
    "Y_val = Y[val_start:val_end]\n",
    "X_train = X[train_start:train_end]\n",
    "Y_train = Y[train_start:train_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./datasets/X_test\", X_test)\n",
    "np.save(\"./datasets/Y_test\", Y_test)\n",
    "np.save(\"./datasets/Y_train\", Y_train)\n",
    "np.save(\"./datasets/X_train\", X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = VesselDataset()\n",
    "dataset_train.load_images(train_start, train_end)\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = VesselDataset()\n",
    "dataset_test.load_images(test_start, test_end)\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation dataset (User 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = VesselDataset()\n",
    "dataset_val.load_images(val_start, val_end)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform image augmentation on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = aug.Sometimes(1.0, [\n",
    "                    aug.Sometimes(1.0, aug.Affine(\n",
    "                               scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                               rotate=(-15, 15)))\n",
    "                ])\n",
    "                \n",
    "#CUSTOM CODE FOR VISUALIZATION\n",
    "# Load and display random samples\n",
    "#image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "#for image_id in image_ids:\n",
    "#    image = dataset_train.load_image(image_id)\n",
    "#    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#    display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEDIT FOR TRAINING THIS<br>\n",
    "Create model in training mode<br>\n",
    "odel = MaskRCNN(mode=\"training\", config=config, model_dir='models/setD')<br>\n",
    "rint(model.keras_model.summary())<br>\n",
    "<br>\n",
    " Train the model<br>\n",
    "odel.train(dataset_train, dataset_val, dataset_test, learning_rate=config.LEARNING_RATE,<br>\n",
    "           epochs=100, layers='all', augmentation=augmentation)<br>\n",
    "odel.keras_model.save('models/setD/setD_mask_rcnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
